{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import unicodedata2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy.sparse import csr_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(text):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    text = (unicodedata2.normalize('NFKD', text)\n",
    "            .encode('ascii', 'ignore')\n",
    "            .decode('utf-8', 'ignore')\n",
    "            .lower())\n",
    "    words = re.sub(r'[^\\w\\s]', '', text).split()\n",
    "    return [wnl.lemmatize(word) for word in words if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tr = basic_clean(''.join(str(train['ABSTRACT'].tolist())))\n",
    "words_tst = basic_clean(''.join(str(test['ABSTRACT'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col=['Analysis of PDEs', 'Applications',\n",
    "       'Artificial Intelligence', 'Astrophysics of Galaxies',\n",
    "       'Computation and Language', 'Computer Vision and Pattern Recognition',\n",
    "       'Cosmology and Nongalactic Astrophysics',\n",
    "       'Data Structures and Algorithms', 'Differential Geometry',\n",
    "       'Earth and Planetary Astrophysics', 'Fluid Dynamics',\n",
    "       'Information Theory', 'Instrumentation and Methods for Astrophysics',\n",
    "       'Machine Learning', 'Materials Science', 'Methodology', 'Number Theory',\n",
    "       'Optimization and Control', 'Representation Theory', 'Robotics',\n",
    "       'Social and Information Networks', 'Statistics Theory',\n",
    "       'Strongly Correlated Electrons', 'Superconductivity',\n",
    "       'Systems and Control']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_col=['Computer Science', 'Mathematics', 'Physics', 'Statistics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_thresholds(true, preds):\n",
    "    thresholds = [i/100 for i in range(100)]\n",
    "    best_thresholds = []\n",
    "    for idx in range(25):\n",
    "        f1_scores = [f1_score(true[:, idx], (preds[:, idx] > thresh) * 1) for thresh in thresholds]\n",
    "        best_thresh = thresholds[np.argmax(f1_scores)]\n",
    "        best_thresholds.append(best_thresh)\n",
    "        \n",
    "    return best_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn, val = train_test_split(train, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_features=30000)\n",
    "combined = words_tr+words_tst\n",
    "vec.fit(combined)\n",
    "\n",
    "trn_abs = vec.transform(trn['ABSTRACT'])\n",
    "val_abs = vec.transform(val['ABSTRACT'])\n",
    "tst_abs = vec.transform(test['ABSTRACT'])\n",
    "\n",
    "trn1 = np.hstack((trn_abs.toarray(), trn[topic_col]))\n",
    "val1 = np.hstack((val_abs.toarray(), val[topic_col]))\n",
    "tst1 = np.hstack((tst_abs.toarray(), test[topic_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn1 = csr_matrix(trn1.astype('int16'))\n",
    "val1 = csr_matrix(val1.astype('int16'))\n",
    "tst1 = csr_matrix(tst1.astype('int16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf1 = OneVsRestClassifier(LogisticRegression(C = 2, n_jobs=-1))\n",
    "clf1.fit(trn1, trn[target_col])\n",
    "\n",
    "val_preds = clf1.predict_proba(val1)\n",
    "best_thresholds = get_best_thresholds(val[target_col].values, val_preds)\n",
    "\n",
    "for i, thresh in enumerate(best_thresholds):\n",
    "  val_preds[:, i] = (val_preds[:, i] > thresh) * 1\n",
    "\n",
    "f1_score(val[target_col], val_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7257266150526717"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(val[target_col], val_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = clf.predict_proba(tst2)\n",
    "\n",
    "for i, thresh in enumerate(best_thresholds):\n",
    "    preds_test[:, i] = (preds_test[:, i] > thresh) * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec2 = CountVectorizer(max_features=40000)\n",
    "_ = vec2.fit(list(train['ABSTRACT']) + list(test['ABSTRACT']))\n",
    "\n",
    "trn_abs = vec2.transform(trn['ABSTRACT'])\n",
    "val_abs = vec2.transform(val['ABSTRACT'])\n",
    "tst_abs = vec2.transform(test['ABSTRACT'])\n",
    "print(trn_abs.shape, val_abs.shape, tst_abs.shape)\n",
    "\n",
    "trn2 = np.hstack((trn_abs.toarray(), trn[topic_col]))\n",
    "val2 = np.hstack((val_abs.toarray(), val[topic_col]))\n",
    "tst2 = np.hstack((tst_abs.toarray(), test[topic_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn2 = csr_matrix(trn2.astype('int16'))\n",
    "val2 = csr_matrix(val2.astype('int16'))\n",
    "tst2 = csr_matrix(tst2.astype('int16'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = OneVsRestClassifier(LogisticRegression(C = 2, n_jobs=-1))\n",
    "clf2.fit(trn2, trn[target_col])\n",
    "\n",
    "val_preds = clf2.predict_proba(val2)\n",
    "best_thresholds = get_best_thresholds(val[target_col].values, val_preds)\n",
    "\n",
    "for i, thresh in enumerate(best_thresholds):\n",
    "  val_preds[:, i] = (val_preds[:, i] > thresh) * 1\n",
    "\n",
    "f1_score(val[target_col], val_preds, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test['id']\n",
    "submission[target_col] = preds_test\n",
    "submission.to_csv('sol4.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
